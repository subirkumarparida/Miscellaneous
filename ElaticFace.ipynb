{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5594d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed26b7",
   "metadata": {},
   "source": [
    "<b>Steps:</b>\n",
    "\n",
    "    1. Download Image dataset\n",
    "    2. Visualize the dataset\n",
    "    3. Preprocessing:\n",
    "        a) Split dataset\n",
    "        b) Image augmentation\n",
    "        c) Data generator\n",
    "    4. Model Architecture\n",
    "        a) Network\n",
    "        b) Loss Function\n",
    "    5. Train model\n",
    "    6. Evaluate model\n",
    "        a) Plot Loss and Accuracy\n",
    "    7. Predict on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2027551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosFace(torch.nn.Module):\n",
    "    def __init__(self, s=64.0, m=0.40):\n",
    "        super(CosFace, self).__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, labels: torch.Tensor):\n",
    "        index = torch.where(labels != -1)[0]\n",
    "        target_logit = logits[index, labels[index].view(-1)]\n",
    "        final_target_logit = target_logit - self.m\n",
    "        logits[index, labels[index].view(-1)] = final_target_logit\n",
    "        logits = logits * self.s\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d6ed71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosFace(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=64.0, m=0.35):\n",
    "        super(CosFace, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.kernel = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        nn.init.normal_(self.kernel, std=0.01)\n",
    "\n",
    "    def forward(self, embbedings, label):\n",
    "        embbedings = l2_norm(embbedings, axis=1)\n",
    "        kernel_norm = l2_norm(self.kernel, axis=0)\n",
    "        cos_theta = torch.mm(embbedings, kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1, 1)  # for numerical stability\n",
    "        index = torch.where(label != -1)[0]\n",
    "        m_hot = torch.zeros(index.size()[0], cos_theta.size()[1])\n",
    "        m_hot.scatter_(1, label[index, None], self.m)\n",
    "        cos_theta[index] -= m_hot\n",
    "        ret = cos_theta * self.s\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7fe51797",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the arguments have invalid types: (!Tensor!, !Tensor!)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4854/2799898734.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCosFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4854/1369772537.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, s, m)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the arguments have invalid types: (!Tensor!, !Tensor!)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "aa = CosFace(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "eec8d4fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4854/3774575049.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_embedding_loss\u001b[0;34m(input1, input2, target, margin, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3458\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3459\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3460\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "input1 = torch.randn(4, 5)\n",
    "input2 = torch.randn(4, 5)\n",
    "output = F.cosine_embedding_loss(input1, input2, input1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "abac3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "?F.cosine_embedding_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d35307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3fc9ee2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1, 2, 3, 4], [3, 4, 2, 2]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ef5eb4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.FloatTensor([1, 2])\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "53765633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 2.], requires_grad=True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a13d386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3a37c996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3cefc92d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (tuple, Tensor), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the arguments have invalid types: (!tuple!, !Tensor!)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4854/1108870862.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (tuple, Tensor), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the arguments have invalid types: (!tuple!, !Tensor!)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "torch.FloatTensor(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2b0c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.mm(a, b)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c390f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 22.,  28.,   8.,   7.],\n",
       "        [-19., -22.,   3.,  10.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c711eb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c3dfcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  1.],\n",
       "        [-1., -1.,  1.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17924308",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = torch.where(c != -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f968b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cf11fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e039d2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(index.size()[0], c.size()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff71b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea79ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96037708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2d(ni, nf, ks, stride=1):\n",
    "    return nn.Conv2d(in_channels=ni, out_channels=nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n",
    "\n",
    "def bn_relu_conv(ni, nf, ks):\n",
    "    return nn.Sequential(nn.BatchNorm2d(ni), \n",
    "                       nn.ReLU(inplace=True),\n",
    "                       conv_2d(ni, nf, ks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d08619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=1):\n",
    "        super().__init__()\n",
    "        if ni > 100:\n",
    "            temp = ni * 2\n",
    "        else:\n",
    "            temp = ni\n",
    "        self.bn = nn.BatchNorm2d(temp)\n",
    "        self.conv1 = conv_2d(temp, ni, 1, stride)\n",
    "        self.conv2 = bn_relu_conv(ni, ni, ks=3)\n",
    "        self.conv3 = bn_relu_conv(ni, nf, ks=1)\n",
    "        self.shortcut = lambda x: x\n",
    "        if ni != nf:\n",
    "            self.shortcut = conv_2d(temp, nf, 1, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"Inside Res Block1\")\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn(x), inplace=True)\n",
    "        #print(x.shape)\n",
    "        r1 = self.shortcut(x)\n",
    "        #print(r1.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x) * 0.2\n",
    "        #print(x.shape)\n",
    "        return x.add_(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11cee5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock2(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=1):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(ni)\n",
    "        self.conv1 = conv_2d(ni, nf, 1, stride)\n",
    "        self.conv2 = bn_relu_conv(nf, nf, ks=3)\n",
    "        self.conv3 = bn_relu_conv(nf, ni, ks=1)\n",
    "        self.shortcut = lambda x: x\n",
    "#        if ni != nf:\n",
    "#            self.shortcut = conv_2d(ni, nf, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"Inside Res Block2\")\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn(x), inplace=True)\n",
    "        #print(x.shape)\n",
    "        r = self.shortcut(x)\n",
    "        #print(r.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x) * 0.2\n",
    "        return x.add_(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6445597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_group(N, ni, nf, stride):\n",
    "    start = ResBlock(ni, nf, stride)\n",
    "    rest = [ResBlock2(nf, ni) for j in range(1, N)]\n",
    "    return [start] + rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb13429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af85093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet(nn.Module):\n",
    "    def __init__(self, n_groups, N, n_classes, k=1, n_start=64):\n",
    "        super().__init__()\n",
    "        #Increase channels\n",
    "        layers = [conv_2d(3, 64, ks=7, stride=2)]\n",
    "        layers += [nn.MaxPool2d(kernel_size=3, stride=2, padding=1)]\n",
    "        n_channels = [n_start]\n",
    "\n",
    "        #Add groups\n",
    "        for i in range(n_groups):\n",
    "            n_channels.append(n_start*(2**i)*k)\n",
    "            stride = 2 if i>0 else 1\n",
    "            layers += make_group(N[i], n_channels[i], n_channels[i]*4, stride)\n",
    "\n",
    "        #Pool, Flatten, and add linear layer for classification  \n",
    "        layers += [nn.BatchNorm2d(n_channels[n_groups]*2),\n",
    "                   nn.ReLU(inplace=True),\n",
    "                   nn.AdaptiveAvgPool2d(1),\n",
    "                   #nn.AvgPool2d(kernel_size=2, stride=2), \n",
    "                   Flatten(), \n",
    "                   nn.Linear(n_channels[n_groups]*2, n_classes)]\n",
    "    \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #a = self.features(x)\n",
    "        #print(a.shape)\n",
    "        return self.features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1871ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of blocks at various groups\n",
    "N_50 = [3, 4, 6, 3]\n",
    "N_101 = [3, 4, 23, 3]\n",
    "N_152 = [3, 8, 36, 3]\n",
    "\n",
    "def ResNet50(n_classes):\n",
    "    return MyResNet(4, N_50, n_classes, k=2)\n",
    "\n",
    "def ResNet101(n_classes):\n",
    "    return MyResNet(4, N_101, n_classes, k=2)\n",
    "\n",
    "def ResNet152(n_classes):\n",
    "    return MyResNet(4, N_152, n_classes, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb95a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8fbaccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyResNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (2): ResBlock(\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): ResBlock2(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock2(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (6): ResBlock2(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): ResBlock2(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (8): ResBlock2(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (9): ResBlock(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (10): ResBlock2(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResBlock2(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResBlock2(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResBlock2(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResBlock2(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResBlock(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (16): ResBlock2(\n",
       "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (17): ResBlock2(\n",
       "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (18): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): AdaptiveAvgPool2d(output_size=1)\n",
       "    (21): Flatten()\n",
       "    (22): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1156e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net = ResNet50(10)\n",
    "    x = torch.randn(2, 3, 300, 300)\n",
    "    y = net(x)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32fec585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b63fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "414a6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_WIP(nn.Module):\n",
    "    def __init__(self, n_groups, N, n_classes, k=1, n_start=64):\n",
    "        super().__init__()\n",
    "        #Increase channels\n",
    "        self.layers = [conv_2d(3, 64, ks=7, stride=2)]\n",
    "        self.layers += [nn.MaxPool2d(kernel_size=3, stride=2, padding=1)]\n",
    "        n_channels = [n_start]\n",
    "\n",
    "        #Add groups\n",
    "        for i in range(n_groups):\n",
    "            n_channels.append(n_start*(2**i)*k)\n",
    "            stride = 2 if i>0 else 1\n",
    "            self.layers += self.make_group(N[i], n_channels[i], n_channels[i]*4, stride)\n",
    "\n",
    "        #Pool, Flatten, and add linear layer for classification  \n",
    "        self.layers += [nn.BatchNorm2d(n_channels[n_groups]*2),\n",
    "                   nn.ReLU(inplace=True),\n",
    "                   nn.AdaptiveAvgPool2d(1),\n",
    "                   #nn.AvgPool2d(kernel_size=2, stride=2), \n",
    "                   Flatten(), \n",
    "                   nn.Linear(n_channels[n_groups]*2, n_classes)]\n",
    "                   #nn.Softmax(dim=1)]\n",
    "    \n",
    "        self.features = nn.Sequential(*self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "    def make_group(self, N, ni, nf, stride):\n",
    "        start = ResBlock(ni, nf, stride)\n",
    "        rest = [ResBlock2(nf, ni) for j in range(1, N)]\n",
    "        return [start] + rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c19ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d562b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dowload the dataset\n",
    "# dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "# download_url(dataset_url, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68328860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract from archive\n",
    "# with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
    "#     tar.extractall(path='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "815887f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test']\n",
      "['deer', 'frog', 'bird', 'cat', 'airplane', 'truck', 'automobile', 'dog', 'horse', 'ship']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/cifar10'\n",
    "\n",
    "print(os.listdir(data_dir))\n",
    "classes = os.listdir(data_dir + \"/train\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96051e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training examples for airplanes: 5000\n",
      "['3211.png', '1794.png', '3863.png', '2290.png', '0683.png']\n"
     ]
    }
   ],
   "source": [
    "airplane_files = os.listdir(data_dir + \"/train/airplane\")\n",
    "print('No. of training examples for airplanes:', len(airplane_files))\n",
    "print(airplane_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52b5c239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of test examples for ship: 1000\n",
      "['0683.png', '0354.png', '0520.png', '0684.png', '0098.png']\n"
     ]
    }
   ],
   "source": [
    "ship_test_files = os.listdir(data_dir + \"/test/ship\")\n",
    "print(\"No. of test examples for ship:\", len(ship_test_files))\n",
    "print(ship_test_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfda9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(data_dir+'/train', transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "00cff6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d9a323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 1\n"
     ]
    }
   ],
   "source": [
    "img, label = dataset[5999]\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07a3c581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "715571cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a65f502b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 5000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = 5000\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9bce86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed032680",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee878b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape: torch.Size([128, 3, 32, 32])\n",
      "out.shape: torch.Size([128, 10])\n",
      "out[127]: tensor([-10.0279,  -7.0471,  -2.2929,   0.6284,  -2.8182,   4.6175,   1.8955,\n",
      "         -4.5241,  -8.0071,  -3.6841], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dl:\n",
    "  print('images.shape:', images.shape)\n",
    "  out = model(images)\n",
    "  print('out.shape:', out.shape)\n",
    "  print('out[127]:', out[127])\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f43bb3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0149e-07, 7.9109e-06, 9.1819e-04, 1.7046e-02, 5.4302e-04, 9.2063e-01,\n",
       "        6.0526e-02, 9.8616e-05, 3.0290e-06, 2.2844e-04],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(out[127], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b25c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cpu')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4db4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "34b8383e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df201a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyResNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (2): ResBlock(\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): ResBlock2(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock2(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (6): ResBlock2(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): ResBlock2(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (8): ResBlock2(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (9): ResBlock(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (10): ResBlock2(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (11): ResBlock2(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (12): ResBlock2(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResBlock2(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResBlock2(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResBlock(\n",
       "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (shortcut): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (16): ResBlock2(\n",
       "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (17): ResBlock2(\n",
       "      (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv2): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv3): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (18): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): AdaptiveAvgPool2d(output_size=1)\n",
       "    (21): Flatten()\n",
       "    (22): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73440f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None, metric=None):\n",
    "  #Generate predictions\n",
    "  preds = model(xb)\n",
    "  #Calculate loss\n",
    "  loss = loss_func(preds, yb)\n",
    "\n",
    "  if opt is not None:\n",
    "    #Compute gradients\n",
    "    loss.backward()\n",
    "    #update parameters\n",
    "    opt.step()\n",
    "    #Reset Gradients\n",
    "    opt.zero_grad()\n",
    "\n",
    "  metric_result = None\n",
    "  if metric is not None:\n",
    "    #compute the metric\n",
    "    metric_result = metric(preds, yb)\n",
    "\n",
    "  return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5a34f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, valid_dl, metric=None):\n",
    "  with torch.no_grad():\n",
    "    #pass each batch through the model\n",
    "    results = [loss_batch(model, loss_fn, xb, yb, metric=metric) for xb, yb in valid_dl]\n",
    "    #separate losses, counts and metrics\n",
    "    losses, nums, metrics = zip(*results)\n",
    "    #Total size of the dataset\n",
    "    total = np.sum(nums)\n",
    "    #Avg. loss across batches\n",
    "    avg_loss = np.sum(np.multiply(losses, nums))/total\n",
    "    avg_metric = None\n",
    "\n",
    "    if metric is not None:\n",
    "      #Avg of metric across batches\n",
    "      avg_metric = np.sum(np.multiply(metrics, nums)) / total\n",
    "\n",
    "    return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c02ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_fn, train_dl, valid_dl, lr=None, metric=None, opt_fn=None):\n",
    "  train_losses, val_losses, val_metrics = [], [], []\n",
    "\n",
    "  #instantiate the optimizer\n",
    "  if opt_fn is None: opt_fn = torch.optim.SGD\n",
    "  opt = opt_fn(model.parameters(), lr=lr)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    #Training\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "      train_loss, _, _ = loss_batch(model, loss_fn, xb, yb, opt)\n",
    "\n",
    "    #Evaluation\n",
    "    model.eval()\n",
    "    result = evaluate(model, loss_fn, valid_dl, metric)\n",
    "    val_loss, total, val_metric = result\n",
    "\n",
    "    #Record the loss and metric\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_metrics.append(val_metric)\n",
    "\n",
    "    #Print progress:\n",
    "    if metric is None:\n",
    "      print('Epoch [{}/{}], Train_loss: {:.4f}, Val_loss: {:.4f}'.format(epoch+1, epochs, train_loss, val_loss))\n",
    "\n",
    "    else:\n",
    "      print('Epoch [{}/{}], Train_loss: {:.4f}, Val_loss: {:.4f}, {}: {:.4f}'.format(epoch+1, epochs, train_loss, val_loss, metric.__name__, val_metric))\n",
    "\n",
    "  return train_losses, val_losses, val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "860fd116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "  _, preds = torch.max(outputs, dim=1)\n",
    "  return torch.sum(preds == labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6cdfc6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, _, val_acc = evaluate(model, F.cross_entropy, val_dl, metric=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "913a3f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3908, Accuracy: 0.0988\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.4f}, Accuracy: {:.4f}'.format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bbdb2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b4a046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train_loss: 2.0396, Val_loss: 3.0050, accuracy: 0.2644\n",
      "Epoch [2/25], Train_loss: 1.7309, Val_loss: 1.7298, accuracy: 0.3820\n",
      "Epoch [3/25], Train_loss: 1.2783, Val_loss: 1.6074, accuracy: 0.4526\n",
      "Epoch [4/25], Train_loss: 1.5224, Val_loss: 1.5383, accuracy: 0.4614\n",
      "Epoch [5/25], Train_loss: 1.2276, Val_loss: 1.3604, accuracy: 0.5154\n",
      "Epoch [6/25], Train_loss: 1.2488, Val_loss: 1.4045, accuracy: 0.5282\n",
      "Epoch [7/25], Train_loss: 0.9580, Val_loss: 1.2232, accuracy: 0.5954\n",
      "Epoch [8/25], Train_loss: 0.8582, Val_loss: 1.2465, accuracy: 0.5966\n",
      "Epoch [9/25], Train_loss: 0.8898, Val_loss: 1.1760, accuracy: 0.6250\n",
      "Epoch [10/25], Train_loss: 0.7302, Val_loss: 1.0789, accuracy: 0.6598\n",
      "Epoch [11/25], Train_loss: 0.5626, Val_loss: 1.2564, accuracy: 0.6038\n",
      "Epoch [12/25], Train_loss: 0.7782, Val_loss: 1.1540, accuracy: 0.6550\n",
      "Epoch [13/25], Train_loss: 0.4934, Val_loss: 1.1349, accuracy: 0.6704\n",
      "Epoch [14/25], Train_loss: 0.5031, Val_loss: 1.1937, accuracy: 0.6642\n",
      "Epoch [15/25], Train_loss: 0.4549, Val_loss: 1.2615, accuracy: 0.6730\n",
      "Epoch [16/25], Train_loss: 0.3610, Val_loss: 1.2373, accuracy: 0.6648\n",
      "Epoch [17/25], Train_loss: 0.3779, Val_loss: 1.2235, accuracy: 0.6836\n",
      "Epoch [18/25], Train_loss: 0.7584, Val_loss: 1.6366, accuracy: 0.6398\n",
      "Epoch [19/25], Train_loss: 0.3082, Val_loss: 1.4515, accuracy: 0.6748\n",
      "Epoch [20/25], Train_loss: 0.1436, Val_loss: 1.6009, accuracy: 0.6754\n",
      "Epoch [21/25], Train_loss: 0.3204, Val_loss: 1.5289, accuracy: 0.6836\n",
      "Epoch [22/25], Train_loss: 0.1292, Val_loss: 1.6851, accuracy: 0.6690\n",
      "Epoch [23/25], Train_loss: 0.0623, Val_loss: 1.5812, accuracy: 0.6946\n",
      "Epoch [24/25], Train_loss: 0.1669, Val_loss: 1.8614, accuracy: 0.6600\n",
      "Epoch [25/25], Train_loss: 0.2460, Val_loss: 1.8454, accuracy: 0.6910\n"
     ]
    }
   ],
   "source": [
    "history = fit(num_epochs, model, F.cross_entropy, train_dl, val_dl, lr, accuracy, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49cd8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_metrics = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f498dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(val_metrics):\n",
    "    #accuracies = [x['val_metrics'] for x in history]\n",
    "    plt.plot(val_metrics, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52ec3417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracies(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4fb6b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    #train_losses = [x.get('train_losses') for x in history]\n",
    "    #val_losses = [x['val_losses'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0263e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a32e59d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e197e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder(data_dir+'/test', transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc7b1c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4717948230743407, 10000, 0.7136)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\n",
    "result = evaluate(model, F.cross_entropy, test_loader, accuracy)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2bfa917",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
